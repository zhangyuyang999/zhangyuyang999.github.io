<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Hadoop | 不二's Blog</title><meta name="keywords" content="Hadoop"><meta name="author" content="Zzzz不二"><meta name="copyright" content="Zzzz不二"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Hadoop">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop">
<meta property="og:url" content="https://zhangyuyang999.github.io/2022/05/13/Hadoop/index.html">
<meta property="og:site_name" content="不二&#39;s Blog">
<meta property="og:description" content="Hadoop">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://zhangyuyang999.github.io/img/hadoop.webp">
<meta property="article:published_time" content="2022-05-13T00:43:21.000Z">
<meta property="article:modified_time" content="2022-05-16T00:32:08.705Z">
<meta property="article:author" content="Zzzz不二">
<meta property="article:tag" content="Hadoop">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://zhangyuyang999.github.io/img/hadoop.webp"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://zhangyuyang999.github.io/2022/05/13/Hadoop/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Hadoop',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-05-16 08:32:08'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.1.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/./img/icon.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data is-center"><div class="data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">8</div></a></div><div class="data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">6</div></a></div><div class="data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 文档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 链接</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/./img/hadoop.webp')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">不二's Blog</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 文档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 链接</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Hadoop</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-05-13T00:43:21.000Z" title="发表于 2022-05-13 08:43:21">2022-05-13</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-05-16T00:32:08.705Z" title="更新于 2022-05-16 08:32:08">2022-05-16</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">9k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>28分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Hadoop"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h1><h2 id="Hadoop概述"><a href="#Hadoop概述" class="headerlink" title="Hadoop概述"></a>Hadoop概述</h2><ul>
<li>狭义上Hadoop指的是Apache的一款开源软件.用java语言实现.主要用来使用简单的编程模型跨计算机集群对大型数据集进行分布式计算处理.</li>
<li>Hadoop核心组件<ul>
<li>Hadoop HDFS-分布式文件存储系统:解决海量数据的存储</li>
<li>Hadoop YARN-集群资源管理和任务调度框架:解决资源的管理和分配</li>
<li>Hadoop MapReduce-分布式计算框架:解决海量数据的计算</li>
</ul>
</li>
</ul>
<h4 id="Hadoop集群介绍"><a href="#Hadoop集群介绍" class="headerlink" title="Hadoop集群介绍"></a>Hadoop集群介绍</h4><ul>
<li>hadoop集群一般指:HDFS集群和YARN集群</li>
<li>两个集群在逻辑上分离(互相不干扰)物理上在一起(处于一个机器的不同进程)</li>
<li>这两个集群都是主从架构</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">Hadoop安装包目录结构</span><br><span class="line"></span><br><span class="line"> bin    #hadoop核心脚本 最基础最底层脚本</span><br><span class="line"> etc    #配置目录</span><br><span class="line"> include</span><br><span class="line"> lib</span><br><span class="line"> libexec</span><br><span class="line"> LICENSE.txt</span><br><span class="line"> NOTICE.txt</span><br><span class="line"> README.txt</span><br><span class="line"> sbin  #服务启动 关闭 维护相关的脚本</span><br><span class="line"> share #官方自带实例  hadoop相关依赖jar</span><br><span class="line"> </span><br><span class="line"> Hadoop初始化和基本命令</span><br><span class="line"> </span><br><span class="line"> hadoop namenode -format #进行初始化, 一般只需要执行一次,首次启动之前.</span><br><span class="line"> 如果多次初始化可能造成主从之间互相不识别.</span><br><span class="line"> # 启动hdfs集群的角色</span><br><span class="line"> hdfs --daemon start|stop namenode|datanode|</span><br><span class="line"> start-dfs.sh </span><br><span class="line"> stop-dfs.sh </span><br><span class="line"> # 启动yarn集群的角色</span><br><span class="line"> yarn --daemon start|stop resourcemanager|nodemanager</span><br><span class="line"> start-yarn.sh</span><br><span class="line"> stop-yarn.sh</span><br><span class="line"> # 也可以一次全部启动</span><br><span class="line"> start-all.sh</span><br><span class="line"> stop-all.sh</span><br></pre></td></tr></table></figure>

<h2 id="Hadoop–HDFS"><a href="#Hadoop–HDFS" class="headerlink" title="Hadoop–HDFS"></a>Hadoop–HDFS</h2><h4 id="HDFS简介"><a href="#HDFS简介" class="headerlink" title="HDFS简介"></a>HDFS简介</h4><ul>
<li><p>HDFS就是一个文件系统用来存储文件和存储数据,是大数据最底层的一个服务,他通过分布式来保存数据.</p>
</li>
<li><p>具备故障检测和快速恢复的能力–容错高</p>
</li>
<li><p>面对海量数据的存储,注重吞吐能力,而不是注重响应时间-延迟高</p>
</li>
<li><p>支持大文件存储–小文件效率较低</p>
</li>
<li><p>一次写入多次读取的模型–不支持修改操作</p>
</li>
<li><p>异构存储,可移植性高</p>
</li>
</ul>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMyMDE4LmNuYmxvZ3MuY29tL2Jsb2cvMTAzNTk0OS8yMDE4MDgvMTAzNTk0OS0yMDE4MDgwMjE0NDMwNDk5NS01ODU5ODIzNjcucG5n?x-oss-process=image/format,png" alt="img"></p>
<ul>
<li>主从架构</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">主角色：namenode  管理维护着元数据：目录树结构 文件 大小 副本 备份 位置信息</span><br><span class="line">从角色：datanode  存储着最终的数据块</span><br><span class="line">NameNode 成了访问HDFS的唯一入口,任何请求都要先请求NameNode 然后通过NameNode来转发给DateNode</span><br><span class="line"># 在每一个datanode节点中 数据都是分块存储的,默认情况下一块是128M</span><br><span class="line"># 超过128M将会分割,不足128M将会直接占用一个块</span><br><span class="line"></span><br><span class="line"># 副本机制,一般默认情况下是3副本模式,本省一份,而外拷贝二份.可以在配置文件中进行修改</span><br></pre></td></tr></table></figure>

<ul>
<li>HDFS-shell操作</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># hadoop fs &lt;args&gt; 文件系统的路径</span><br><span class="line">HDFS的shell命令和linux很相似 就是在linux命令前加hadoop fs -</span><br><span class="line">例如 hadoop fs -ls hdfs://node1:8020/ 查看目录结构</span><br><span class="line">hadoop fs -mkdir /test 创建目录</span><br><span class="line">hadoop fs -put src  dst</span><br><span class="line">将单个 src 或多个 srcs 从本地文件系统复制到目标文件系统</span><br><span class="line">	#src代表的是本地目录 所谓的本地指的是客户端所在的机器 </span><br><span class="line">	#dst代表的是HDFS</span><br><span class="line">#追加内容到文件尾部 # hadoop fs -appendToFile 2.txt 3.txt /1.txt</span><br><span class="line">#合并下载 getmerge</span><br><span class="line">合并下载多个文件  其功能和appendToFile相反的动作</span><br><span class="line">hadoop fs -getmerge /small/* ./merge.txt</span><br><span class="line">这些命令都可以通过加一定的参数来满足一定的需求</span><br><span class="line">https://hadoop.apache.org/docs/r3.3.0/hadoop-project-dist/hadoop-common/FileSystemShell.html</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>NameNode职责</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1.NameNode仅存储HDFS的元数据：文件系统中所有文件的目录树，并跟踪整个集群中的文件，不存储实际数据。</span><br><span class="line">2.NameNode知道HDFS中任何给定文件的块列表及其位置。使用此信息NameNode知道如何从块中构建文件。</span><br><span class="line">3.NameNode不持久化存储每个文件中各个块所在的datanode的位置信息，这些信息会在系统启动时从DataNode重建。</span><br><span class="line">4.NameNode是Hadoop集群中的单点故障。</span><br><span class="line">5.NameNode所在机器通常会配置有大量内存（RAM）。</span><br></pre></td></tr></table></figure>

<ul>
<li>DateNode职责</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1.DataNode负责最终数据块block的存储。是集群的从角色，也称为Slave。</span><br><span class="line">2.DataNode启动时，会将自己注册到NameNode并汇报自己负责持有的块列表。</span><br><span class="line">3.当某个DataNode关闭时，不会影响数据的可用性。 NameNode将安排由其他DataNode管理的块进行副本复制。</span><br><span class="line">4.DataNode所在机器通常配置有大量的硬盘空间，因为实际数据存储在DataNode中。</span><br></pre></td></tr></table></figure>

<ul>
<li>SecondartNameNode职责</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.除了DataNode和NameNode之外，还有另一个守护进程，它称为secondary NameNode。充当NameNode的辅助节点，但不能替代NameNode。</span><br><span class="line">2.当NameNode启动时，NameNode合并Fsimage和edits log文件以还原当前文件系统名称空间。如果edits log过大不利于加载，Secondary NameNode就辅助NameNode从NameNode下载Fsimage文件和edits log文件进行合并。</span><br><span class="line">3.NameNode在启动后会在自己的内存中进行fsimage和log文件的合并,运行过程中的合并由SecondartNameNode负责</span><br></pre></td></tr></table></figure>

<hr>
<h4 id="HDFS-工作机制-上传文件流程-写文件流程"><a href="#HDFS-工作机制-上传文件流程-写文件流程" class="headerlink" title="HDFS-工作机制-上传文件流程(写文件流程)"></a>HDFS-工作机制-上传文件流程(写文件流程)</h4><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMyMDE4LmNuYmxvZ3MuY29tL2Jsb2cvMTAzNTk0OS8yMDE4MDgvMTAzNTk0OS0yMDE4MDgwMjE0NDIxMTgzOC0xMzgxMDk4NjA2LnBuZw?x-oss-process=image/format,png" alt="img"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># Pipeline管道简介</span><br><span class="line">Pipeline，中文翻译为管道。这是HDFS在上传文件写数据过程中采用的一种数据传输方式。</span><br><span class="line">客户端将数据块写入第一个数据节点，第一个数据节点保存数据之后再将块复制到第二个数据节点，后者保存后将其复制到第三个数据节点。</span><br><span class="line">为什么datanode之间采用pipeline线性传输，而不是一次给三个datanode拓扑式传输呢？</span><br><span class="line">因为数据以管道的方式，顺序的沿着一个方向传输，这样能够充分利用每个机器的带宽，避免网络瓶颈和高延迟时的连接，最小化推送所有数据的延时。</span><br><span class="line">在线性推送模式下，每台机器所有的出口宽带都用于以最快的速度传输数据，而不是在多个接受者之间分配宽带。</span><br><span class="line"># 默认三副本存储策略</span><br><span class="line">第一块副本：优先客户端本地，否则随机</span><br><span class="line">第二块副本：不同于第一块副本的不同机架。</span><br><span class="line">第三块副本：第二块副本相同机架不同机器。</span><br></pre></td></tr></table></figure>

<ul>
<li>HDFS写数据流程</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">1.hdfs客户端读取文件内容,然后连接NameNode请求上传文件(RPC)</span><br><span class="line">2.NameNode接收请求,进行检查校验判断客户端是否能上传文件.检查通过NameNode会为本次请求记下一条记录,返回输出流给客户端写数据.</span><br><span class="line">3.客户端通过输出流开始写数据</span><br><span class="line">4.客户端写入数据时，将数据分成一个个数据包（packet 默认64k）,并写入一个内部数据队列（data queue）。有一个内部类做DataStreamer，用于请求NameNode挑选出适合存储数据副本的一组DataNode，默认是3副本存储。DataStreamer将数据包流式传输到pipeline的第一个DataNode,该DataNode存储数据包并将它发送到pipeline的第二个DataNode。同样，第二个DataNode存储数据包并且发送给第三个（也是最后一DataNode。</span><br><span class="line">5.OutputStream也维护着一个内部数据包队列来等待DataNode的收到确认回执，称之为确认队列（ack queue）,收到pipeline中所有DataNode确认信息后，该数据包才会从确认队列删除。</span><br><span class="line">6.客户端完成数据写入后，在FSDataOutputStream输出流上调用close()方法关闭。</span><br><span class="line">7.DistributedFileSystem联系NameNode告知其文件写入完成，等待NameNode确认。</span><br><span class="line">因为namenode已经知道文件由哪些块组成（DataStream请求分配数据块），因此仅需等待最小复制块即可成功返回。最小复制是由参数dfs.namenode.replication.min指定，默认是1.</span><br></pre></td></tr></table></figure>

<h4 id="HDFS–工作机制–下载文件流程-读文件流程"><a href="#HDFS–工作机制–下载文件流程-读文件流程" class="headerlink" title="HDFS–工作机制–下载文件流程(读文件流程)"></a>HDFS–工作机制–下载文件流程(读文件流程)</h4><ul>
<li>HDFS读数据流程</li>
</ul>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMyMDE4LmNuYmxvZ3MuY29tL2Jsb2cvMTAzNTk0OS8yMDE4MDgvMTAzNTk0OS0yMDE4MDgwMjE0NDA0ODc5Mi03NzY5OTE5NTIucG5n?x-oss-process=image/format,png" alt="img"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1、HDFS客户端创建FileSystem对象实例DistributedFileSystem， FileSystem封装了与文件系统操作的相关方法。调用DistributedFileSystem对象的open()方法来打开希望读取的文件。</span><br><span class="line">2、DistributedFileSystem使用RPC调用namenode来确定文件中前几个块的块位置（分批次读取）信息。对于每个块，namenode返回具有该块所有副本的datanode位置地址列表，并且该地址列表是排序好的，与客户端的网络拓扑距离近的排序靠前。</span><br><span class="line">3、DistributedFileSystem将FSDataInputStream输入流返回到客户端以供其读取数据。</span><br><span class="line">4、客户端在FSDataInputStream输入流上调用read()方法。然后，已存储DataNode地址的InputStream连接到文件中第一个块的最近的DataNode。数据从DataNode流回客户端，结果客户端可以在流上重复调用read（）。</span><br><span class="line">5、当该块结束时，InputStream将关闭与DataNode的连接，然后寻找下一个块的最佳datanode。这些操作对用户来说是透明的。所以用户感觉起来它一直在读取一个连续的流。</span><br><span class="line">客户端从流中读取数据时，也会根据需要询问NameNode来检索下一批数据块的DataNode位置信息。</span><br><span class="line">6、一旦客户端完成读取，就对FSDataInputStream调用close()方法。 </span><br></pre></td></tr></table></figure>

<h4 id="NameNode和DataNode之间的通信"><a href="#NameNode和DataNode之间的通信" class="headerlink" title="NameNode和DataNode之间的通信"></a>NameNode和DataNode之间的通信</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">启动时，DataNode需要向NameNode注册自己并汇报自己持有的数据块信息；</span><br><span class="line">工作时，主从之间有心跳机制，数据块汇报机制；</span><br><span class="line">DataNode会定期（dfs.heartbeat.interval配置项配置，默认是3秒）向NameNode发送心跳，如果NameNode长时间没有接受到DataNode发送的心跳， NameNode就会认为该DataNode失效。</span><br><span class="line">DataNode会定期向NameNode进行自己持有的数据块信息汇报，汇报时间间隔取参数dfs.blockreport.intervalMsec,参数未配置的话默认为6小时。</span><br></pre></td></tr></table></figure>

<h4 id="NameNode原数据管理"><a href="#NameNode原数据管理" class="headerlink" title="NameNode原数据管理"></a>NameNode原数据管理</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">按存储形式分为内存元数据和元数据文件两种，分别存在内存和磁盘上。</span><br><span class="line">1.内存元数据</span><br><span class="line">    为了保证用户操作元数据交互高效，延迟低，NameNode把所有的元数据都存储在内存中，我们叫做内存元数据。内存中的元数据是最完整的，包括文件自身属性信息、文件块位置映射信息。</span><br><span class="line">    但是内存的致命问题是，断点数据丢失，数据不会持久化。因此NameNode又辅佐了元数据文件来保证元数据的安全完整。</span><br><span class="line">2.元数据文件有两种：fsimage内存镜像文件、Edits log编辑日志。</span><br><span class="line">fsimage 内存镜像文件</span><br><span class="line">    是内存元数据的一个持久化的检查点。但是fsimage中仅包含Hadoop文件系统中文件自身属性相关的元数据信息，但不包含文件块位置的信息。文件块位置信息只存储在内存中，是由datanode启动加入集群的时候，向namenode进行数据块的汇报得到的，并且后续间断指定时间进行数据块报告。</span><br><span class="line">    持久化的动作是数据从内存到磁盘的IO过程。会对namenode正常服务造成一定的影响，不能频繁的进行持久化。</span><br><span class="line">Edits log编辑日志</span><br><span class="line">    为了避免两次持久化之间数据丢失的问题，又设计了Edits log编辑日志文件。文件中记录的是HDFS所有更改操作（文件创建，删除或修改）的日志，文件系统客户端执行的更改操作首先会被记录到edits文件中。</span><br></pre></td></tr></table></figure>

<h4 id="SecondartNameNode职责"><a href="#SecondartNameNode职责" class="headerlink" title="SecondartNameNode职责"></a>SecondartNameNode职责</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">因此为了克服上述问题，需要一个易于管理的机制来帮助我们减小edit logs文件的大小和得到一个最新的fsimage文件，这样也会减小在NameNode上的压力。</span><br><span class="line">Checkpoint核心是把fsimage与edits log合并以生成新的fsimage的过程。</span><br><span class="line">结果：fsimage版本不断更新不会太旧、edits log文件不会太大。</span><br><span class="line"># checkpoint流程</span><br><span class="line">1、当触发checkpoint操作条件时，SNN发送请求给NN滚动edits log。</span><br><span class="line">然后NN会生成一个新的编辑日志文件：edits new，便于记录后续操作记录。</span><br><span class="line">2、SNN会将旧的edits log文件和上次fsimage复制到自己本地（使用HTTP GET方式）。</span><br><span class="line">3、SNN首先将fsimage载入到内存，然后一条一条地执行edits文件中的操作，使得内存中的fsimage不断更新，这个过程就是edits和fsimage文件合并。合并结束，SNN将内存中的数据dump生成一个新的fsimage文件。</span><br><span class="line">4、SNN将新生成的Fsimage new文件复制到NN节点。至此刚好是一个轮回，等待下一次checkpoint触发SecondaryNameNode进行工作，一直这样循环操作。</span><br></pre></td></tr></table></figure>

<h4 id="数据损坏处理"><a href="#数据损坏处理" class="headerlink" title="数据损坏处理"></a>数据损坏处理</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">当DataNode读取block的时候，它会计算checksum。</span><br><span class="line">如果计算后的checksum，与block创建时候的值不一样，那么就可以说明block以及损坏。</span><br><span class="line">Client读取其他DN上的block。</span><br><span class="line">NameNode标记该块已经损坏，然后复制block达到预期设置的文件的备份数。</span><br><span class="line">DataNode在其他的文件创建后的三周验证它的checksum。</span><br></pre></td></tr></table></figure>



<h4 id="HDFS–安全模式"><a href="#HDFS–安全模式" class="headerlink" title="HDFS–安全模式"></a>HDFS–安全模式</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">安全模式（safe mode）是HDFS集群处于一种保护状态，文件系统只可以读，不可以写。</span><br><span class="line">#在HDFS集群刚启动时候 会自动进入安全模式</span><br><span class="line">自动解除安全模式条件</span><br><span class="line">#1、条件1:已经汇报的block达到总数据块的 0.999</span><br><span class="line">#2、条件2:存活的dn数量大于等于0  说明这个条件不严格</span><br><span class="line">#3、条件3:满足12条件的情况下 持续30s 结束自动离开安全模式</span><br><span class="line">#为什么集群刚启动的时候 要进入安全模式 </span><br><span class="line">文件系统元数据不完整 无法对外提供可高的文件服务  属于内部的元数据汇报、校验、构建的过程。</span><br><span class="line"># 手动进入和离开</span><br><span class="line">hdfs dfsadmin -safemode enter</span><br><span class="line">hdfs dfsadmin -safemode leave</span><br><span class="line"></span><br><span class="line">Safe mode is ON. It was turned on manually. Use &quot;hdfs dfsadmin -safemode leave&quot; to turn safe mode off.</span><br><span class="line"></span><br><span class="line">#运维人员可以手动进入安全模式 进行集群的维护升级等动作 避免了群起群停浪费时间。</span><br></pre></td></tr></table></figure>

<h4 id="HDFS–垃圾桶机制"><a href="#HDFS–垃圾桶机制" class="headerlink" title="HDFS–垃圾桶机制"></a>HDFS–垃圾桶机制</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">在默认情况下 hdfs没有垃圾桶 意味着删除操作直接物理删除文件。</span><br><span class="line">但是可以通过core-site.xml中开启垃圾桶机制.指定保存在垃圾桶的时间。单位分钟</span><br><span class="line">配置好之后 再删除文件  直接进入垃圾桶</span><br><span class="line">垃圾桶的本质就是hdfs上的一个隐藏目录。</span><br><span class="line">后悔了 需要恢复怎么做？</span><br><span class="line">  hadoop fs -cp /user/root/.Trash/Current/itcast.txt /</span><br><span class="line">就想直接删除文件 就在删除命令加-skipTrash</span><br></pre></td></tr></table></figure>



<h2 id="Hadoop–MapReduce"><a href="#Hadoop–MapReduce" class="headerlink" title="Hadoop–MapReduce"></a>Hadoop–MapReduce</h2><h4 id="MapReduce思想"><a href="#MapReduce思想" class="headerlink" title="MapReduce思想"></a>MapReduce思想</h4><ul>
<li>Map负责“拆分”：即把复杂的任务分解为若干个“简单的子任务”来并行处理。可以进行拆分的前提是这些小任务可以并行计算，彼此间几乎没有依赖关系。</li>
<li>Reduce负责“合并”：即对map阶段的结果进行全局汇总。</li>
</ul>
<h4 id="MapReduce特点"><a href="#MapReduce特点" class="headerlink" title="MapReduce特点"></a>MapReduce特点</h4><ul>
<li>易于编程<ul>
<li>Mapreduce框架提供了用于二次开发的接口；简单地实现一些接口，就可以完成一个分布式程序。任务计算交给计算框架去处理，将分布式程序部署到hadoop集群上运行，集群节点可以扩展到成百上千个等。</li>
</ul>
</li>
<li>良好的扩展性<ul>
<li>当计算机资源不能得到满足的时候，可以通过增加机器来扩展它的计算能力。基于MapReduce的分布式计算得特点可以随节点数目增长保持近似于线性的增长，这个特点是MapReduce处理海量数据的关键，通过将计算节点增至几百或者几千可以很容易地处理数百TB甚至PB级别的离线数据。</li>
</ul>
</li>
<li>高容错性<ul>
<li>Hadoop集群是分布式搭建和部署得，任何单一机器节点宕机了，它可以把上面的计算任务转移到另一个节点上运行，不影响整个作业任务得完成，过程完全是由Hadoop内部完成的。</li>
</ul>
</li>
<li>适合海量数据的离线处理<ul>
<li>可以处理GB、TB和PB级别得数据量</li>
</ul>
</li>
</ul>
<h4 id="MapReduce局限性"><a href="#MapReduce局限性" class="headerlink" title="MapReduce局限性"></a>MapReduce局限性</h4><ul>
<li>实时计算性能差<ul>
<li>MapReduce主要应用于离线作业，无法作到秒级或者是亚秒级得数据响应。</li>
</ul>
</li>
<li>不能进行流式计算<ul>
<li>流式计算特点是数据是源源不断得计算，并且数据是动态的；而MapReduce作为一个离线计算框架，主要是针对静态数据集得，数据是不能动态变化得。</li>
</ul>
</li>
</ul>
<h4 id="MapReduce架构体系"><a href="#MapReduce架构体系" class="headerlink" title="MapReduce架构体系"></a>MapReduce架构体系</h4><p>一个完整的MapReduce程序在分布式运行时有三类</p>
<ul>
<li>MRAppMaster: 负责整个程序的过程调度及状态协调(配合YARN)</li>
<li>MapTask:负责map阶段的整个数据处理流程</li>
<li>ReduceTask:负责reduce阶段的整个数据处理流程</li>
</ul>
<p>阶段组成</p>
<ul>
<li>MapReduce编程模型只能包含一个Map阶段和一个Reduce阶段</li>
<li>如果业务逻辑非常复杂,可以采用多个MapReduce串行运行</li>
</ul>
<p>MapReduce数据类型</p>
<ul>
<li>整个MapReduce程序中,数据都是以kv键值对的形式传递的</li>
<li>在实际编程解决各种业务问题中,需要考虑每个阶段的输入输出KV是什么</li>
<li>MapReduce内置很多默认操作,如排序分组都和数据的K有关</li>
</ul>
<h4 id="MapReduce执行流程"><a href="#MapReduce执行流程" class="headerlink" title="MapReduce执行流程"></a>MapReduce执行流程</h4><h5 id="整体流程"><a href="#整体流程" class="headerlink" title="整体流程"></a>整体流程</h5><p><img src="https://img-blog.csdnimg.cn/c322ff0b54fa434b93625d8f6fa2eb2e.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_Q1NETiBAU2hvY2thbmc=,size_103,color_FFFFFF,t_70,g_se,x_16" alt="MR工作流程"></p>
<h6 id="分片、格式化数据源"><a href="#分片、格式化数据源" class="headerlink" title="分片、格式化数据源"></a>分片、格式化数据源</h6><p>输入 Map 阶段的数据源，必须经过分片和格式化操作。</p>
<ul>
<li>分片操作：指的是将源文件划分为大小相等的小数据块( Hadoop 2.x 中默认 128MB )，也就是分片( split )，Hadoop 会为每一个分片构建一个 Map 任务，并由该任务运行自定义的 map() 函数，从而处理分片里的每一条记录;</li>
<li>格式化操作：将划分好的分片( split )格式化为键值对&lt;key,value&gt;形式的数据，其中， key 代表偏移量， value 代表每一行内容。</li>
</ul>
<h6 id="执行-MapTask"><a href="#执行-MapTask" class="headerlink" title="执行 MapTask"></a>执行 MapTask</h6><p>每个 Map 任务都有一个内存缓冲区(缓冲区大小 100MB )，输入的分片( split )数据经过 Map 任务处理后的中间结果会写入内存缓冲区中。<br>如果写人的数据达到内存缓冲的阈值( 80MB )，会启动一个线程将内存中的溢出数据写入磁盘，同时不影响 Map 中间结果继续写入缓冲区。<br>在溢写过程中， MapReduce 框架会对 key 进行排序，如果中间结果比较大，会形成多个溢写文件，最后的缓冲区数据也会全部溢写入磁盘形成一个溢写文件，如果是多个溢写文件，则最后合并所有的溢写文件为一个文件。</p>
<h6 id="执行-Shuffle-过程"><a href="#执行-Shuffle-过程" class="headerlink" title="执行 Shuffle 过程"></a>执行 Shuffle 过程</h6><p>MapReduce 工作过程中， Map 阶段处理的数据如何传递给 Reduce 阶段，这是 MapReduce 框架中关键的一个过程，这个过程叫作 Shuffle 。<br>Shuffle 会将 MapTask 输出的处理结果数据分发给 ReduceTask ，并在分发的过程中，对数据按 key 进行分区和排序。</p>
<h6 id="执行-ReduceTask"><a href="#执行-ReduceTask" class="headerlink" title="执行 ReduceTask"></a>执行 ReduceTask</h6><p>输入 ReduceTask 的数据流是&lt;key, {value list}&gt;形式，用户可以自定义 reduce()方法进行逻辑处理，最终以&lt;key, value&gt;的形式输出。</p>
<h6 id="写入文件"><a href="#写入文件" class="headerlink" title="写入文件"></a>写入文件</h6><p>MapReduce 框架会自动把 ReduceTask 生成的&lt;key, value&gt;传入 OutputFormat 的 write 方法，实现文件的写入操作。</p>
<h5 id="Map阶段"><a href="#Map阶段" class="headerlink" title="Map阶段"></a>Map阶段</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">1、准备工作</span><br><span class="line">	:HDFS待处理的文件（200M），两个block对应两个分片（split），对应两个Maptask</span><br><span class="line"></span><br><span class="line">2、客户端submit前</span><br><span class="line">	:获取待处理的信息，根据参数配置，形成任务分配规划</span><br><span class="line">		:如 - txt1(0-128M),txt2(128-200M)</span><br><span class="line">3、客户端正式提交</span><br><span class="line">	:wc.jar,job.xml</span><br><span class="line"></span><br><span class="line">4、客户端向RM发出请求</span><br><span class="line"></span><br><span class="line">5、Resourcemanager执行的任务过程</span><br><span class="line">	:根据分片的个数计算出Maptask数量</span><br><span class="line">	:指定nodemanager开启APPmaster</span><br><span class="line"></span><br><span class="line">6、使用textinputformat读取数据,并进行逻辑运算默认</span><br><span class="line">	:Ⅰ、InputFormat读取txt1文件</span><br><span class="line">	:Ⅱ、底层使用记录读取器RecorderReader读取内存</span><br><span class="line">	:Ⅲ、调用read读取k1，v1</span><br><span class="line">			默认是按行读取数据。key是每一行的起始位置偏移量，value是本行的文本内容。</span><br><span class="line">	:Ⅳ、调用mapper方法，生成k2，v2</span><br><span class="line"></span><br><span class="line">7、计算完毕后将计算结果k2，v2写入到缓冲区</span><br><span class="line">	:元数据 - 索引、分区、分区数、key的开始至，value的开始</span><br><span class="line">	:记录 - 记录的key，记录的values，未使用区域</span><br><span class="line"></span><br><span class="line">8、在内存进行分区排序</span><br><span class="line">	:分区规则 - 当前key的hash值对reduce个数进行求余数(默认,可以自定义)</span><br><span class="line">	:排序规则 - 快排</span><br><span class="line"></span><br><span class="line">9、当内存数据超过阈值，0.8后，会溢写数据到磁盘，形成小文件</span><br><span class="line">	:磁盘文件分区且区内有序</span><br><span class="line"></span><br><span class="line">10、磁盘中的小文件最后会归并排序</span><br><span class="line">	:将分区号相同的小文件合并成一个文件</span><br><span class="line"></span><br><span class="line">11、Combiner，按照各个分区进行本地聚合</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="Reduce阶段"><a href="#Reduce阶段" class="headerlink" title="Reduce阶段"></a>Reduce阶段</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">1、按照分区号通过http协议跨节点拉取到reducetask本地磁盘;</span><br><span class="line"></span><br><span class="line">2、将拉取到的多个map端文件进行归并排序，生成一个排序后的文件</span><br><span class="line"></span><br><span class="line">3、将文件装载到内存，进行聚合操作</span><br><span class="line"></span><br><span class="line">4、输出计算结果到HDFS，输出格式由outputformat.recordwriter控制</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="Shuffle阶段"><a href="#Shuffle阶段" class="headerlink" title="Shuffle阶段"></a>Shuffle阶段</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">map阶段shuffle大致流程</span><br><span class="line">1、每个map有一个环形内存缓冲区，用于存储map的输出。</span><br><span class="line">		:默认大小为100MB，一旦达到阈值0.8，一个后台线程就将内容写入到磁盘的指定目录的一个新建文件中</span><br><span class="line">    </span><br><span class="line">2、写磁盘前，要partition(哈希取模分区，余数就是分区编号)，sort。</span><br><span class="line">    	:如果有combiner，combiner排序后写数据</span><br><span class="line">    		:commbiner:本地聚合可缓解reducetask计算压力(默认没有,有的数据无法通过结合来介绍量)</span><br><span class="line">    	:内存中排序算法为快排</span><br><span class="line">3、等最后记录写完，合并全部文件为一个分区且排序的文件</span><br><span class="line">    	:小文件合并排序算法为归并排序</span><br><span class="line">___________________________________________________________________</span><br><span class="line">1、在生成map之前，会计算文件分片的大小,然后会根据分片的大小计算map的个数，</span><br><span class="line">	对每一个分片都会产生一个map作业，或者是一个文件（小于分片大小*1.1）生成一个map作业，然后通过自定的map方法进行自定义的逻辑计算，计算完毕后会写到本地磁盘;</span><br><span class="line">2、在这里不是直接写入磁盘，为了保证IO效率，采用了先写入内存的环形缓冲区，并做一次预排序（快速排序）。</span><br><span class="line">	缓冲区的大小默认为100MB（可通过修改配置项mpareduce.task.io.sort.mb进行修改），当写入内存缓冲区的大小到达一定比例时，默认为80%（可通过mapreduce.map.sort.spill.percent配置项修改）,将启动一个溢写线程将内存缓冲区的内容溢写到磁盘（spill to disk），这个溢写线程是独立的，不影响map向缓冲区写结果的线程，在溢写到磁盘的过程中，map继续输入到缓冲中，如果期间缓冲区被填满，则map写会被阻塞到溢写磁盘过程完成。</span><br><span class="line">	溢写是通过轮询的方式将缓冲区中的内存写入到本地mapreduce.cluster.local.dir目录下。在溢写到磁盘之前，我们会知道reduce的数量，然后会根据reduce的数量划分分区，默认根据hashpartition对溢写的数据写入到相对应的分区。</span><br><span class="line">	在每个分区中，后台线程会根据key进行排序，所以溢写到磁盘的文件是分区且排序的。如果有combiner函数，它在排序后的输出运行，使得map输出更紧凑。减少写到磁盘的数据和传输给reduce的数据。    </span><br><span class="line">    每次环形换冲区的内存达到阈值时，就会溢写到一个新的文件，因此当一个map溢写完之后，本地会存在多个分区切排序的文件。在map完成之前会把这些文件合并成一个分区且排序(归并排序)的文件，可以通过参数mapreduce.task.io.sort.factor控制每次可以合并多少个文件。</span><br><span class="line">___________________________________________________________________</span><br><span class="line">Reduce shuffle阶段大致流程:</span><br><span class="line">	1、Reducer通过http协议得到输出文件的特定分区的数据</span><br><span class="line">		reducetask1:负责分区1和分区3的数据聚合，通过http协议将对应分区数据拉取过来，拉去内存中</span><br><span class="line">			:内存阈值是0.8，多余的落磁盘</span><br><span class="line">	2、全部拉取过来后,进行排序合并map输出,然后走reduce阶段</span><br><span class="line">	3、reduce执行完毕之后,写入到HDFS中</span><br><span class="line">	</span><br><span class="line">	map任务完成后，监控作业状态的application master便知道map的执行情况，并启动reduce任务，application master并且知道map输出和主机之间的对应映射关系，reduce轮询application master便知道主机所要复制的数据。</span><br><span class="line">     一个Map任务的输出，可能被多个Reduce任务抓取。每个Reduce任务可能需要多个Map任务的输出作为其特殊的输入文件，而每个Map任务的完成时间可能不同，当有一个Map任务完成时，Reduce任务就开始运行。Reduce任务根据分区号在多个Map输出中抓取（fetch）对应分区的数据，这个过程也就是Shuffle的copy过程.   </span><br><span class="line">    reduce有少量的复制线程，因此能够并行的复制map的输出，默认为5个线程。可以通过参数mapreduce.reduce.shuffle.parallelcopies控制。   </span><br><span class="line">    这个复制过程和map写入磁盘过程类似，也有阀值和内存大小，阀值一样可以在配置文件里配置，而内存大小是直接使用reduce的tasktracker的内存大小，复制时候reduce还会进行排序操作和合并文件操作。</span><br><span class="line">   如果map输出很小，则会被复制到Reducer所在节点的内存缓冲区，缓冲区的大小可以通过mapred-site.xml文件中的mapreduce.reduce.shuffle.input.buffer.percent指定。一旦Reducer所在节点的内存缓冲区达到阀值，或者缓冲区中的文件数达到阀值，则合并溢写到磁盘。 </span><br><span class="line">   如果map输出较大，则直接被复制到Reducer所在节点的磁盘中。随着Reducer所在节点的磁盘中溢写文件增多，后台线程会将它们合并为更大且有序的文件。当完成复制map输出，进入sort阶段。这个阶段通过归并排序逐步将多个map输出小文件合并成大文件。最后几个通过归并合并成的大文件作为reduce的输出。</span><br></pre></td></tr></table></figure>

<p>MapReduce处理数据截断问题</p>
<ul>
<li>每个maptask都多处理下一个数据块的第一行数据</li>
<li>如果自己不是第一个maptask,都舍弃自己的第一行不处理,从第二行开始处理</li>
</ul>
<h2 id="Hadoop–YARN"><a href="#Hadoop–YARN" class="headerlink" title="Hadoop–YARN"></a>Hadoop–YARN</h2><h4 id="YARN简介"><a href="#YARN简介" class="headerlink" title="YARN简介"></a>YARN简介</h4><ul>
<li>Apache Hadoop YARN （Yet Another Resource Negotiator，另一种资源协调者）是一种新的Hadoop资源管理器。</li>
<li>YARN是一个<strong>通用</strong>资源管理系统和调度平台，可为上层应用提供统一的资源管理和调度。</li>
<li>它的引入为集群在利用率、资源统一管理和数据共享等方面带来了巨大好处。</li>
</ul>
<h4 id="YARN三大组件"><a href="#YARN三大组件" class="headerlink" title="YARN三大组件"></a>YARN三大组件</h4><ul>
<li><p>ResourceManager(RM)</p>
<ul>
<li><p>YARN集群中的主角色，决定系统中所有应用程序之间资源分配的最终权限，即最终仲裁者。</p>
<p>接收用户的作业提交，并通过NM分配、管理各个机器上的计算资源。</p>
</li>
</ul>
</li>
<li><p>NodeManager(NM)</p>
<ul>
<li><p>YARN中的从角色，一台机器上一个，负责管理本机器上的计算资源。</p>
<p>根据RM命令，启动Container容器、监视容器的资源使用情况。并且向RM主角色汇报资源使用情况。</p>
</li>
</ul>
</li>
<li><p>ApplicationMaster</p>
<ul>
<li>用户提交的每个应用程序均包含一个AM。应用程序内的“老大”，负责程序内部各阶段的资源申请，监督程序的执行情况。</li>
</ul>
</li>
<li><p>核心交互流程</p>
</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/2020061011414074.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI4NDI3NjIx,size_16,color_FFFFFF,t_70" alt="img"></p>
<h4 id="YARN运行流程"><a href="#YARN运行流程" class="headerlink" title="YARN运行流程"></a>YARN运行流程</h4><p><img src="https://img-blog.csdnimg.cn/20200610114229924.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI4NDI3NjIx,size_16,color_FFFFFF,t_70" alt="img"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">1.用户向YARN中提交应用程序，其中包括ApplicationMaster程序、启动ApplicationMaster的命令、用户程序等。</span><br><span class="line">2.ResourceManager为该应用程序分配第一个Container，并与对应的Node-Manager通信，要求它在这个Container中启动应用程序的ApplicationMaster。</span><br><span class="line">3.ApplicationMaster首先向ResourceManager注册，这样用户可以直接通过ResourceManager查看应用程序的运行状态，然后它将为各个任务申请资源，并监控它的运行状态，直到运行结束，即重复步骤4~7。</span><br><span class="line">4.ApplicationMaster采用轮询的方式通过RPC协议向ResourceManager申请和领取资源。</span><br><span class="line">5.一旦ApplicationMaster申请到资源后，便与对应的NodeManager通信，要求它启动任务。</span><br><span class="line">6.NodeManager为任务设置好运行环境（包括环境变量、JAR包、二进制程序等）后，将任务启动命令写到一个脚本中，并通过运行该脚本启动任务。</span><br><span class="line">7.各个任务通过某个RPC协议向ApplicationMaster汇报自己的状态和进度，以让ApplicationMaster随时掌握各个任务的运行状态，从而可以在任务失败时重新启动任务。在应用程序运行过程中，用户可随时通过RPC向ApplicationMaster查询应用程序的当前运行状态。</span><br><span class="line">8.应用程序运行完成后，ApplicationMaster向ResourceManager注销并关闭自己。</span><br></pre></td></tr></table></figure>

<h5 id="Yarn任务调度器"><a href="#Yarn任务调度器" class="headerlink" title="Yarn任务调度器"></a>Yarn任务调度器</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">理想情况下，我们应用对 Yarn 资源的请求应该立刻得到满足，但现实情况资源往往是</span><br><span class="line">有限的，特别是在一个很繁忙的集群，一个应用资源的请求经常需要等待一段时间才能的到</span><br><span class="line">相应的资源。在 n Yarn 中，负责给应用分配资源的就是 Scheduler。其实调度本身就是一个难题，很难找到一个完美的策略可以解决所有的应用场景。为此，Yarn 提供了多种调度器</span><br><span class="line">在 Yarn 中有三种调度器可以选择：FIFO Scheduler(先进先出) ，Capacity Scheduler，FairScheduler</span><br><span class="line">2.Capacity Scheduler</span><br><span class="line">Capacity 调度器允许多个组织共享整个集群，每个组织可以获得集群的一部分计算能</span><br><span class="line">力。通过为每个组织分配专门的队列，然后再为每个队列分配一定的集群资源，这样整个集</span><br><span class="line">群就可以通过设置多个队列的方式给多个组织提供服务了。除此之外，队列内部又可以垂直</span><br><span class="line">划分，这样一个组织内部的多个成员就可以共享这个队列资源了，在一个队列内部，资源的</span><br><span class="line">调度是采用的是先进先出(FIFO)策略。</span><br><span class="line">3.FairScheduler</span><br><span class="line">在Fair调度器中，我们不需要预先占用一定的系统资源，Fair调度器会为所有运行的job动态的调整系统资源。如下图所示，当第一个大job提交时，只有这一个job在运行，此时它获得了所有集群资源；当第二个小任务提交后，Fair调度器会分配一半资源给这个小任务，让这两个任务公平的共享集群资源。</span><br><span class="line">  需要注意的是，从第二个任务提交到获得资源会有一定的延迟，因为它需要等待第一个任务释放占用的Container。小任务执行完成之后也会释放自己占用的资源，大任务又获得了全部的系统资源。最终的效果就是Fair调度器即得到了高的资源利用率又能保证小任务及时完成。</span><br></pre></td></tr></table></figure>

<h5 id="队列树"><a href="#队列树" class="headerlink" title="队列树"></a>队列树</h5><ul>
<li>在YARN中，有<strong>层级队列组织</strong>方法，它们构成一个树结构，且根队列叫做root。</li>
<li>对于任何一个应用，都可以显式地指定它属于的队列，也可以不指定从而使用default队列。</li>
<li>在YARN WebUI界面上可以看到默认的队列组织情况。</li>
</ul>
<h2 id="Hadoop–HA集群"><a href="#Hadoop–HA集群" class="headerlink" title="Hadoop–HA集群"></a>Hadoop–HA集群</h2><h4 id="高可用HA简介"><a href="#高可用HA简介" class="headerlink" title="高可用HA简介"></a>高可用HA简介</h4><ul>
<li><strong>高可用性</strong>（英语：high availability，缩写为 <strong>HA</strong>），IT术语，指系统无中断地执行其功能的能力，代表系统的可用性程度。是进行系统设计时的准则之一。</li>
<li>高可用性系统意味着系统服务可以更长时间运行，通常通过提高系统的容错能力来实现。</li>
<li>高可用性或者高可靠度的系统不会希望有单点故障造成整体故障的情形。一般可以通过<strong>冗余</strong>的方式增加多个相同机能的部件，只要这些部件没有同时失效，系统（或至少部分系统）仍可运作，这会让可靠度提高。</li>
</ul>
<h4 id="HA系统设计核心问题（1）"><a href="#HA系统设计核心问题（1）" class="headerlink" title="HA系统设计核心问题（1）"></a>HA系统设计核心问题（1）</h4><ul>
<li><p>脑裂问题</p>
<ul>
<li>脑裂(split-brain)是指“大脑分裂”,本是医学名词。 在HA集群中，脑裂指的是当联系主备节点的”心跳线”断开时(即两个节点断开联系时)，本来为一个整体、动作协调的HA系统，就分裂成为两个独立的节点。由于相互失去了联系，主备节点之间像”裂脑人”一样，使得整个集群处于混乱状态。</li>
</ul>
</li>
<li><p>脑裂的严重后果</p>
<ul>
<li><p>1）集群无主：都认为对方是状态好的，自己是备份角色，后果是无服务；</p>
<p> 2）集群多主：都认为对方是故障的，自己是主角色。相互争抢共享资源，结果会导致系统混乱，数据损坏。此外对于客户端访问也是一头雾水，找谁呢？</p>
<p> 避免脑裂问题的核心是：保持任意时刻系统有且只有一个主角色提供服务。</p>
</li>
</ul>
</li>
<li><p>主备切换、脑裂问题解决–ZKFailoverControll(zkfc)</p>
<ul>
<li><strong>ZK Failover Controller</strong>（ZKFC）是一个ZooKeeper客户端。主要职责：<ul>
<li>监视和管理NameNode健康状态.ZKFC通过命令<strong>监视的</strong>NameNode节点及机器的健康状态。</li>
<li>维持和ZK集群联系.如果本地NameNode运行状况良好，并且ZKFC看到当前没有其他节点持有锁znode，它将自己尝试获取该锁。如果成功，则表明它“赢得了<strong>选举</strong>”，并负责运行故障转移以使其本地NameNode处于Active状态。如果已经有其他节点持有锁，zkfc选举失败，则会对该节点注册监听，等待下次继续选举.</li>
</ul>
</li>
<li><strong>主备切换、脑裂问题解决</strong>–Fencing（隔离）机制<ul>
<li>故障转移过程也就是俗称的主备角色切换的过程，切换过程中最怕的就是脑裂的发生。因此需要Fencing机制来避免，将先前的Active节点隔离，然后将Standby转换为Active状态。</li>
<li>Hadoop公共库中对外提供了两种Fenching实现，分别是sshfence和shellfence（缺省实现）。</li>
<li><strong>sshfence</strong>是指通过ssh登陆目标节点上，使用命令fuser将进程杀死（通过tcp端口号定位进程pid，该方法比jps命令更准确).</li>
<li>shellfence是指执行一个用户事先定义的shell命令（脚本）完成隔离。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="HA系统设计核心问题（2）"><a href="#HA系统设计核心问题（2）" class="headerlink" title="HA系统设计核心问题（2）"></a><strong>HA</strong>系统设计核心问题（2）</h4><ul>
<li>数据状态同步问题<ul>
<li>主备切换保证服务持续可用性的前提是主备节点之间的状态、数据是一致的，或者说准一致的。如果说备用的节点和主节点之间的数据差距过大，即使完成了主备切换的动作，那也是没有意义的。 数据同步常见做法是：通过日志重演操作记录。主角色正常提供服务，发生的事务性操作通过日志记录，备用角色读取日志重演操作。</li>
</ul>
</li>
<li>问题解决<ul>
<li>Journal Node（<strong>JN</strong>）集群是轻量级分布式系统，主要用于高速读写数据、存储数据。</li>
<li>通常使用<strong>2N+1</strong>台JournalNode存储共享<strong>Edits Log</strong>（编辑日志）。–底层类似于zk的分布式一致性算法。</li>
<li>任何修改操作在 Active NN上执行时，JournalNode进程同时也会记录edits log到<strong>至少半数</strong>以上的JN中，这时 Standby NN 监测到JN 里面的同步log发生变化了会读取JN里面的edits log，然后重演操作记录同步到自己的目录镜像树里面。</li>
</ul>
</li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Zzzz不二</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://zhangyuyang999.github.io/2022/05/13/Hadoop/">https://zhangyuyang999.github.io/2022/05/13/Hadoop/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://zhangyuyang999.github.io" target="_blank">不二's Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Hadoop/">Hadoop</a></div><div class="post_share"><div class="social-share" data-image="/./img/hadoop.webp" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/05/14/Hive/"><img class="prev-cover" src="/./img/hive.webp" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Hive</div></div></a></div><div class="next-post pull-right"><a href="/2022/04/23/Zookeeper/"><img class="next-cover" src="/./img/zookeeper.webp" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Zookeeper解析</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="lv-container" data-id="city" data-uid="MTAyMC81NTgxNC8zMjI3OQ=="></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/./img/icon.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Zzzz不二</div><div class="author-info__description">一个菜鸟程序员</div></div><div class="card-info-data is-center"><div class="card-info-data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">8</div></a></div><div class="card-info-data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">6</div></a></div><div class="card-info-data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/zhangyuyang999"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/zhangyuyang999" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:1057869258@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="https://space.bilibili.com/403782330?spm_id_from=333.1007.0.0" target="_blank" title="bilibili"><i class="fa-brands fa-bilibili"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">一名菜鸟程序员的Blog！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Hadoop"><span class="toc-number">1.</span> <span class="toc-text">Hadoop</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Hadoop%E6%A6%82%E8%BF%B0"><span class="toc-number">1.1.</span> <span class="toc-text">Hadoop概述</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Hadoop%E9%9B%86%E7%BE%A4%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.1.0.1.</span> <span class="toc-text">Hadoop集群介绍</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hadoop%E2%80%93HDFS"><span class="toc-number">1.2.</span> <span class="toc-text">Hadoop–HDFS</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#HDFS%E7%AE%80%E4%BB%8B"><span class="toc-number">1.2.0.1.</span> <span class="toc-text">HDFS简介</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#HDFS-%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6-%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6%E6%B5%81%E7%A8%8B-%E5%86%99%E6%96%87%E4%BB%B6%E6%B5%81%E7%A8%8B"><span class="toc-number">1.2.0.2.</span> <span class="toc-text">HDFS-工作机制-上传文件流程(写文件流程)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#HDFS%E2%80%93%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6%E2%80%93%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6%E6%B5%81%E7%A8%8B-%E8%AF%BB%E6%96%87%E4%BB%B6%E6%B5%81%E7%A8%8B"><span class="toc-number">1.2.0.3.</span> <span class="toc-text">HDFS–工作机制–下载文件流程(读文件流程)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#NameNode%E5%92%8CDataNode%E4%B9%8B%E9%97%B4%E7%9A%84%E9%80%9A%E4%BF%A1"><span class="toc-number">1.2.0.4.</span> <span class="toc-text">NameNode和DataNode之间的通信</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#NameNode%E5%8E%9F%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86"><span class="toc-number">1.2.0.5.</span> <span class="toc-text">NameNode原数据管理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#SecondartNameNode%E8%81%8C%E8%B4%A3"><span class="toc-number">1.2.0.6.</span> <span class="toc-text">SecondartNameNode职责</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E6%8D%9F%E5%9D%8F%E5%A4%84%E7%90%86"><span class="toc-number">1.2.0.7.</span> <span class="toc-text">数据损坏处理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#HDFS%E2%80%93%E5%AE%89%E5%85%A8%E6%A8%A1%E5%BC%8F"><span class="toc-number">1.2.0.8.</span> <span class="toc-text">HDFS–安全模式</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#HDFS%E2%80%93%E5%9E%83%E5%9C%BE%E6%A1%B6%E6%9C%BA%E5%88%B6"><span class="toc-number">1.2.0.9.</span> <span class="toc-text">HDFS–垃圾桶机制</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hadoop%E2%80%93MapReduce"><span class="toc-number">1.3.</span> <span class="toc-text">Hadoop–MapReduce</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#MapReduce%E6%80%9D%E6%83%B3"><span class="toc-number">1.3.0.1.</span> <span class="toc-text">MapReduce思想</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#MapReduce%E7%89%B9%E7%82%B9"><span class="toc-number">1.3.0.2.</span> <span class="toc-text">MapReduce特点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#MapReduce%E5%B1%80%E9%99%90%E6%80%A7"><span class="toc-number">1.3.0.3.</span> <span class="toc-text">MapReduce局限性</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#MapReduce%E6%9E%B6%E6%9E%84%E4%BD%93%E7%B3%BB"><span class="toc-number">1.3.0.4.</span> <span class="toc-text">MapReduce架构体系</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#MapReduce%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B"><span class="toc-number">1.3.0.5.</span> <span class="toc-text">MapReduce执行流程</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%95%B4%E4%BD%93%E6%B5%81%E7%A8%8B"><span class="toc-number">1.3.0.5.1.</span> <span class="toc-text">整体流程</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%88%86%E7%89%87%E3%80%81%E6%A0%BC%E5%BC%8F%E5%8C%96%E6%95%B0%E6%8D%AE%E6%BA%90"><span class="toc-number">1.3.0.5.1.1.</span> <span class="toc-text">分片、格式化数据源</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E6%89%A7%E8%A1%8C-MapTask"><span class="toc-number">1.3.0.5.1.2.</span> <span class="toc-text">执行 MapTask</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E6%89%A7%E8%A1%8C-Shuffle-%E8%BF%87%E7%A8%8B"><span class="toc-number">1.3.0.5.1.3.</span> <span class="toc-text">执行 Shuffle 过程</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E6%89%A7%E8%A1%8C-ReduceTask"><span class="toc-number">1.3.0.5.1.4.</span> <span class="toc-text">执行 ReduceTask</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%86%99%E5%85%A5%E6%96%87%E4%BB%B6"><span class="toc-number">1.3.0.5.1.5.</span> <span class="toc-text">写入文件</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Map%E9%98%B6%E6%AE%B5"><span class="toc-number">1.3.0.5.2.</span> <span class="toc-text">Map阶段</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Reduce%E9%98%B6%E6%AE%B5"><span class="toc-number">1.3.0.5.3.</span> <span class="toc-text">Reduce阶段</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Shuffle%E9%98%B6%E6%AE%B5"><span class="toc-number">1.3.0.5.4.</span> <span class="toc-text">Shuffle阶段</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hadoop%E2%80%93YARN"><span class="toc-number">1.4.</span> <span class="toc-text">Hadoop–YARN</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#YARN%E7%AE%80%E4%BB%8B"><span class="toc-number">1.4.0.1.</span> <span class="toc-text">YARN简介</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#YARN%E4%B8%89%E5%A4%A7%E7%BB%84%E4%BB%B6"><span class="toc-number">1.4.0.2.</span> <span class="toc-text">YARN三大组件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#YARN%E8%BF%90%E8%A1%8C%E6%B5%81%E7%A8%8B"><span class="toc-number">1.4.0.3.</span> <span class="toc-text">YARN运行流程</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Yarn%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6%E5%99%A8"><span class="toc-number">1.4.0.3.1.</span> <span class="toc-text">Yarn任务调度器</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%98%9F%E5%88%97%E6%A0%91"><span class="toc-number">1.4.0.3.2.</span> <span class="toc-text">队列树</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hadoop%E2%80%93HA%E9%9B%86%E7%BE%A4"><span class="toc-number">1.5.</span> <span class="toc-text">Hadoop–HA集群</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%AB%98%E5%8F%AF%E7%94%A8HA%E7%AE%80%E4%BB%8B"><span class="toc-number">1.5.0.1.</span> <span class="toc-text">高可用HA简介</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#HA%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E6%A0%B8%E5%BF%83%E9%97%AE%E9%A2%98%EF%BC%881%EF%BC%89"><span class="toc-number">1.5.0.2.</span> <span class="toc-text">HA系统设计核心问题（1）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#HA%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E6%A0%B8%E5%BF%83%E9%97%AE%E9%A2%98%EF%BC%882%EF%BC%89"><span class="toc-number">1.5.0.3.</span> <span class="toc-text">HA系统设计核心问题（2）</span></a></li></ol></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/05/14/Hive/" title="Hive"><img src="/./img/hive.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Hive"/></a><div class="content"><a class="title" href="/2022/05/14/Hive/" title="Hive">Hive</a><time datetime="2022-05-14T00:43:21.000Z" title="发表于 2022-05-14 08:43:21">2022-05-14</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/05/13/Hadoop/" title="Hadoop"><img src="/./img/hadoop.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Hadoop"/></a><div class="content"><a class="title" href="/2022/05/13/Hadoop/" title="Hadoop">Hadoop</a><time datetime="2022-05-13T00:43:21.000Z" title="发表于 2022-05-13 08:43:21">2022-05-13</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/04/23/Zookeeper/" title="Zookeeper解析"><img src="/./img/zookeeper.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Zookeeper解析"/></a><div class="content"><a class="title" href="/2022/04/23/Zookeeper/" title="Zookeeper解析">Zookeeper解析</a><time datetime="2022-04-22T23:43:21.000Z" title="发表于 2022-04-23 07:43:21">2022-04-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/04/19/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%8C%83%E5%BC%8F/" title="数据库范式"><img src="/./img/sql_NF.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="数据库范式"/></a><div class="content"><a class="title" href="/2022/04/19/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%8C%83%E5%BC%8F/" title="数据库范式">数据库范式</a><time datetime="2022-04-19T12:00:11.000Z" title="发表于 2022-04-19 20:00:11">2022-04-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/04/13/MySQL%E6%95%B0%E6%8D%AE%E5%BA%93/" title="MySQL"><img src="/./img/dog.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="MySQL"/></a><div class="content"><a class="title" href="/2022/04/13/MySQL%E6%95%B0%E6%8D%AE%E5%BA%93/" title="MySQL">MySQL</a><time datetime="2022-04-13T00:43:21.000Z" title="发表于 2022-04-13 08:43:21">2022-04-13</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('/./img/hadoop.webp')"><div id="footer-wrap"><div class="copyright">&copy;2022 By Zzzz不二</div><div class="footer_custom_text">凡是过往 皆是序章 😼</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><div class="js-pjax"><script>function loadLivere () {
  if (typeof LivereTower === 'object') {
    window.LivereTower.init()
  }
  else {
    (function(d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') { return; }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;
        e.parentNode.insertBefore(j, e);
    })(document, 'script');
  }
}

if ('Livere' === 'Livere' || !false) {
  if (false) btf.loadComment(document.getElementById('lv-container'), loadLivere)
  else loadLivere()
}
else {
  function loadOtherComment () {
    loadLivere()
  }
}</script></div><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-heart.min.js" async="async" mobile="false"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>